from src.llms import OpenAIEmbeddings
from src.vectorstores.tags import TagsVector

tags_vector = TagsVector(
    folder_path="./.cache",
    index_name="index",
    embeddings=OpenAIEmbeddings(),
)

# 多类型标签 + 语义文本
samples = [
    (["生日", "朋友", "惊喜"], "今天是我的生日，朋友们为我准备了惊喜派对。", {"category": "事件"}),
    (["分手", "悲伤", "独处"], "我们分手了，我一个人坐在路边哭了很久。", {"category": "情感"}),
    (["猫", "温暖", "陪伴"], "我的猫趴在我腿上呼噜呼噜地睡觉，好温暖。", {"category": "宠物"}),
    (["量子力学", "纠缠"], "量子纠缠是量子力学中最神秘的现象之一。", {"category": "科学"}),
    (["山中", "自然", "宁静"], "我在山中小屋中醒来，窗外是鸟鸣和阳光。", {"category": "场景"}),
    (
        ["奥运", "金牌", "竞技"],
        "中国在奥运会上取得了多枚金牌，太振奋人心了。",
        {"category": "体育"},
    ),
    (["工作", "压力", "焦虑"], "老板临时安排了很多任务，我感到非常焦虑。", {"category": "职场"}),
    (["抹茶", "奶茶", "饮品"], "今天我尝了新品抹茶奶茶，味道超级好喝！", {"category": "饮食"}),
    (["咖啡", "放松"], "我今天喝了杯咖啡，心情放松了不少。", {"category": "饮食"}),
    (["小猫", "依赖"], "我家小猫越来越黏人了。", {"category": "宠物"}),
    (["奥运", "热血"], "看到奥运比赛我热血沸腾。", {"category": "体育"}),
    (["量子计算", "研究"], "最新的量子计算研究取得了突破。", {"category": "科技"}),
    (["冥想", "山林", "平静"], "在山林中独自冥想，感觉无比平静。", {"category": "心理"}),
    (["考试", "失利", "沮丧"], "这次考试成绩不理想，我有点沮丧。", {"category": "教育"}),
    (["演唱会", "兴奋"], "昨天的演唱会太震撼了，我嗓子都喊哑了！", {"category": "娱乐"}),
    (["回家", "团聚", "温馨"], "春节终于回到家，和爸妈一起吃饭真的很幸福。", {"category": "家庭"}),
    (["旅游", "风景", "放松"], "这次云南之旅让我彻底放松了心情。", {"category": "旅行"}),
    (["高铁", "晚点", "烦躁"], "高铁又晚点了，真的太耽误事了。", {"category": "出行"}),
    (["下雨", "情绪低落"], "连着几天下雨，感觉心情都被压抑了。", {"category": "天气"}),
]


# 添加数据
for tags, text, metadata in samples:
    tags_vector.add_tags(tags, text, metadata)

# 保存索引
# tags_vector.save_local()

# 查询测试
queries = [
    "我今天喝了杯拿铁，整个人都放松了",
    "最近压力太大了，工作完全压得我喘不过气",
    "我真的很想念我的小猫，它总是趴在我身边陪着我",
    "高考失败了，我感觉人生都灰暗了",
    "去山里静养几天，听着鸟叫，内心得到平静",
    "看到中国选手拿金牌那一刻我眼泪都下来了",
    "刚从云南回来，那里风景太美了，好想再去一次",
    "听了一场震撼的演唱会，感觉自己被音乐治愈了",
    "这几天一直下雨，心情特别低落",
    "我们终于分手了，我走在街头，不知该去哪",
    "我妈今天做了我最爱吃的红烧肉，超幸福",
    "朋友们为我办了个派对，真的超级感动",
    "昨晚喝了一杯新品奶茶，甜到心坎里",
    "我看到量子计算的新闻，未来真的很奇妙",
    "我家猫最近老往我身上跳，好有安全感",
    "高铁又晚点了，我真的受够了出差",
]


# 查询结果打印
for query in queries:
    results = tags_vector.similarity_search_with_score(query, extract_high_score=True)
    print(f"\n查询: {query}")
    for doc, score in results:
        print(f"- 内容: {doc.page_content} | 分数: {score:.4f}")


"""results_high_gap = [
    ("doc1", 1.25),
    ("doc2", 1.22),
    ("doc3", 1.20),
    ("doc4", 0.75),
    ("doc5", 0.73),
    ("doc6", 0.71),
    ("doc7", 0.7),
    ("doc8", 0.69),
]
print(TagsVector.extract_high_score(results_high_gap, fallback_k=2))"""
